{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\roths\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/8.9 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.7/8.9 MB 29.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.3-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 7.6/38.7 MB 39.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 16.5/38.7 MB 40.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.4/38.7 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.1/38.7 MB 36.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.1/38.7 MB 33.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.7 MB 30.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.7 MB 30.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.7 MB 30.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.7/38.7 MB 22.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000028B76E78BD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/9f/71/34ddbd21f1da67c7a768146968b4d0220ee6831e4bcbad3e03dd3eae88b6/scikit_learn-1.7.2-cp311-cp311-win_amd64.whl\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       dtype  count  missing\n",
      "ResponseId             int64  65437        0\n",
      "MainBranch            object  65437        0\n",
      "Age                   object  65437        0\n",
      "Employment            object  65437        0\n",
      "RemoteWork            object  54806    10631\n",
      "...                      ...    ...      ...\n",
      "JobSatPoints_11      float64  29445    35992\n",
      "SurveyLength          object  56182     9255\n",
      "SurveyEase            object  56238     9199\n",
      "ConvertedCompYearly  float64  23435    42002\n",
      "JobSat               float64  29126    36311\n",
      "\n",
      "[114 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"dtype\": df.dtypes,\n",
    "    \"count\": df.count(),\n",
    "    \"missing\": df.isna().sum()\n",
    "})\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>CompTotal</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>JobSatPoints_1</th>\n",
       "      <th>JobSatPoints_4</th>\n",
       "      <th>JobSatPoints_5</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>3.374000e+04</td>\n",
       "      <td>29658.000000</td>\n",
       "      <td>29324.000000</td>\n",
       "      <td>29393.000000</td>\n",
       "      <td>29411.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29448.00000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29445.000000</td>\n",
       "      <td>2.343500e+04</td>\n",
       "      <td>29126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>2.963841e+145</td>\n",
       "      <td>11.466957</td>\n",
       "      <td>18.581094</td>\n",
       "      <td>7.522140</td>\n",
       "      <td>10.060857</td>\n",
       "      <td>24.343232</td>\n",
       "      <td>22.96522</td>\n",
       "      <td>20.278165</td>\n",
       "      <td>16.169432</td>\n",
       "      <td>10.955713</td>\n",
       "      <td>9.953948</td>\n",
       "      <td>8.615529e+04</td>\n",
       "      <td>6.935041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18890.179119</td>\n",
       "      <td>5.444117e+147</td>\n",
       "      <td>9.168709</td>\n",
       "      <td>25.966221</td>\n",
       "      <td>18.422661</td>\n",
       "      <td>21.833836</td>\n",
       "      <td>27.089360</td>\n",
       "      <td>27.01774</td>\n",
       "      <td>26.108110</td>\n",
       "      <td>24.845032</td>\n",
       "      <td>22.906263</td>\n",
       "      <td>21.775652</td>\n",
       "      <td>1.867570e+05</td>\n",
       "      <td>2.088259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16360.000000</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.271200e+04</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49078.000000</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.079715e+05</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>1.000000e+150</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.625660e+07</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
       "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
       "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
       "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
       "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
       "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
       "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
       "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
       "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
       "\n",
       "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
       "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
       "mean         7.522140       10.060857       24.343232        22.96522   \n",
       "std         18.422661       21.833836       27.089360        27.01774   \n",
       "min          0.000000        0.000000        0.000000         0.00000   \n",
       "25%          0.000000        0.000000        0.000000         0.00000   \n",
       "50%          0.000000        0.000000       20.000000        15.00000   \n",
       "75%          5.000000       10.000000       30.000000        30.00000   \n",
       "max        100.000000      100.000000      100.000000       100.00000   \n",
       "\n",
       "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
       "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
       "mean        20.278165       16.169432        10.955713         9.953948   \n",
       "std         26.108110       24.845032        22.906263        21.775652   \n",
       "min          0.000000        0.000000         0.000000         0.000000   \n",
       "25%          0.000000        0.000000         0.000000         0.000000   \n",
       "50%         10.000000        5.000000         0.000000         0.000000   \n",
       "75%         25.000000       20.000000        10.000000        10.000000   \n",
       "max        100.000000      100.000000       100.000000       100.000000   \n",
       "\n",
       "       ConvertedCompYearly        JobSat  \n",
       "count         2.343500e+04  29126.000000  \n",
       "mean          8.615529e+04      6.935041  \n",
       "std           1.867570e+05      2.088259  \n",
       "min           1.000000e+00      0.000000  \n",
       "25%           3.271200e+04      6.000000  \n",
       "50%           6.500000e+04      7.000000  \n",
       "75%           1.079715e+05      8.000000  \n",
       "max           1.625660e+07     10.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Countries: 185\n",
      "Country\n",
      "United States of America                                11095\n",
      "NaN                                                      6507\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom of Great Britain and Northern Ireland     3224\n",
      "                                                        ...  \n",
      "Micronesia, Federated States of...                          1\n",
      "Nauru                                                       1\n",
      "Chad                                                        1\n",
      "Djibouti                                                    1\n",
      "Solomon Islands                                             1\n",
      "Name: count, Length: 186, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(\"Unique Countries:\", df['Country'].nunique())\n",
    "print(df['Country'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States      11095\n",
      "Germany             4947\n",
      "India               4231\n",
      "United Kingdom      3224\n",
      "Ukraine             2672\n",
      "                   ...  \n",
      "Micronesia             1\n",
      "Nauru                  1\n",
      "Chad                   1\n",
      "Djibouti               1\n",
      "Solomon Islands        1\n",
      "Name: count, Length: 185, dtype: int64 \n",
      "\n",
      "EdLevel\n",
      "Bachelor's        24942\n",
      "Master's          15557\n",
      "Some College       7651\n",
      "High School        5793\n",
      "Doctorate          2970\n",
      "Associate's        1793\n",
      "Primary School     1146\n",
      "Something else      932\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "country_mapping = {\n",
    "    'United States of America': 'United States',\n",
    "    'USA': 'United States',\n",
    "    'U.S.A.': 'United States',\n",
    "    'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n",
    "    'UK': 'United Kingdom',\n",
    "    'U.K.': 'United Kingdom',\n",
    "    'Micronesia, Federated States of...': 'Micronesia',\n",
    "    # add more after inspecting your data\n",
    "}\n",
    "\n",
    "edlevel_mapping = {\n",
    "    \"Bachelor’s degree (B.A., B.S., B.Eng., etc.)\": \"Bachelor's\",\n",
    "    \"Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\": \"Master's\",\n",
    "    \"Some college/university study without earning a degree\": \"Some College\",\n",
    "    \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\": \"High School\",\n",
    "    \"Primary/elementary school\": \"Primary School\",\n",
    "    \"Professional degree (JD, MD, Ph.D, Ed.D, etc.)\": \"Doctorate\",\n",
    "    \"Associate degree (A.A., A.S., etc.)\": \"Associate's\"\n",
    "}\n",
    "\n",
    "\n",
    "df_exploded = df.explode('Languages')\n",
    "\n",
    "df['Country'] = df['Country'].replace(country_mapping)\n",
    "\n",
    "df['EdLevel'] = df['EdLevel'].replace(edlevel_mapping)\n",
    "\n",
    "print (df['Country'].value_counts(),\"\\n\")\n",
    "print (df['EdLevel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Employment_list  Employment_Not employed, and not looking for work  \\\n",
      "0  [Employed, full-time]                                                  0   \n",
      "1  [Employed, full-time]                                                  0   \n",
      "2  [Employed, full-time]                                                  0   \n",
      "3   [Student, full-time]                                                  0   \n",
      "4   [Student, full-time]                                                  0   \n",
      "\n",
      "   Employment_Independent contractor, freelancer, or self-employed  \\\n",
      "0                                                  0                 \n",
      "1                                                  0                 \n",
      "2                                                  0                 \n",
      "3                                                  0                 \n",
      "4                                                  0                 \n",
      "\n",
      "   Employment_Employed, part-time  Employment_Employed, full-time  \\\n",
      "0                               0                               1   \n",
      "1                               0                               1   \n",
      "2                               0                               1   \n",
      "3                               0                               0   \n",
      "4                               0                               0   \n",
      "\n",
      "   Employment_Student, full-time  Employment_I prefer not to say  \\\n",
      "0                              0                               0   \n",
      "1                              0                               0   \n",
      "2                              0                               0   \n",
      "3                              1                               0   \n",
      "4                              1                               0   \n",
      "\n",
      "   Employment_Retired  Employment_Not employed, but looking for work  \\\n",
      "0                   0                                              0   \n",
      "1                   0                                              0   \n",
      "2                   0                                              0   \n",
      "3                   0                                              0   \n",
      "4                   0                                              0   \n",
      "\n",
      "   Employment_Student, part-time  \n",
      "0                              0  \n",
      "1                              0  \n",
      "2                              0  \n",
      "3                              0  \n",
      "4                              0  \n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Split into lists and strip\n",
    "df['Employment_list'] = df['Employment'].str.split(';')\n",
    "df['Employment_list'] = df['Employment_list'].apply(lambda x: [e.strip() for e in x])\n",
    "\n",
    "# Get unique employment types\n",
    "all_employment_types = set([item for sublist in df['Employment_list'] for item in sublist])\n",
    "\n",
    "# Create one-hot columns (no duplicates)\n",
    "for emp_type in all_employment_types:\n",
    "    col_name = f'Employment_{emp_type}'\n",
    "    df[col_name] = df['Employment_list'].apply(lambda x: int(emp_type in x))\n",
    "\n",
    "one_hot_cols = [col for col in df.columns if col.startswith('Employment_')]\n",
    "print(df[one_hot_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lang_MicroPython  Lang_Dart  Lang_GDScript  Lang_Delphi  Lang_Nim  \\\n",
      "0                 0          0              0            0         0   \n",
      "1                 0          0              0            0         0   \n",
      "2                 0          0              0            0         0   \n",
      "3                 0          0              0            0         0   \n",
      "4                 0          0              0            0         0   \n",
      "\n",
      "   Lang_Lua  Lang_Julia  Lang_R  Lang_Prolog  Lang_JavaScript  ...  \\\n",
      "0         0           0       0            0                0  ...   \n",
      "1         0           0       0            0                1  ...   \n",
      "2         0           0       0            0                0  ...   \n",
      "3         0           0       0            0                1  ...   \n",
      "4         1           0       0            0                1  ...   \n",
      "\n",
      "   Lang_Scala  Lang_C++  Lang_Go  Lang_Fortran  Lang_Haskell  Lang_Swift  \\\n",
      "0           0         0        0             0             0           0   \n",
      "1           0         0        1             0             0           0   \n",
      "2           0         0        0             0             0           0   \n",
      "3           0         1        0             0             0           0   \n",
      "4           0         1        0             0             0           0   \n",
      "\n",
      "   Lang_Java  Lang_Kotlin  Lang_F#  Lang_Clojure  \n",
      "0          0            0        0             0  \n",
      "1          1            0        0             0  \n",
      "2          0            0        0             0  \n",
      "3          1            0        0             0  \n",
      "4          0            0        0             0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split into lists, handle NaN, and strip whitespace\n",
    "df['Language_list'] = df['LanguageHaveWorkedWith'].fillna('').str.split(';')\n",
    "df['Language_list'] = df['Language_list'].apply(lambda x: [e.strip() for e in x if e.strip() != ''])\n",
    "\n",
    "# Get unique languages\n",
    "all_languages = set([item for sublist in df['Language_list'] for item in sublist])\n",
    "\n",
    "# Create one-hot columns (no duplicates)\n",
    "for lang in all_languages:\n",
    "    col_name = f'Lang_{lang}'\n",
    "    df[col_name] = df['Language_list'].apply(lambda x: int(lang in x))\n",
    "\n",
    "# Drop intermediate list column\n",
    "df = df.drop(columns=['Language_list'])\n",
    "\n",
    "# Select only the one-hot encoded columns\n",
    "one_hot_cols = [col for col in df.columns if col.startswith('Lang_')]\n",
    "print(df[one_hot_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[list_col] = df[col].fillna('').str.split(';')\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[list_col] = df[col].fillna('').str.split(';')\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\509596805.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[list_col].apply(lambda x: int(item in x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DatabaseHaveWorkedWith_BigQuery  DatabaseHaveWorkedWith_Elasticsearch  \\\n",
      "0                                0                                     0   \n",
      "1                                0                                     0   \n",
      "2                                0                                     0   \n",
      "3                                0                                     0   \n",
      "4                                0                                     0   \n",
      "\n",
      "   DatabaseHaveWorkedWith_Oracle  DatabaseHaveWorkedWith_Solr  \\\n",
      "0                              0                            0   \n",
      "1                              0                            0   \n",
      "2                              0                            0   \n",
      "3                              0                            0   \n",
      "4                              0                            0   \n",
      "\n",
      "   DatabaseHaveWorkedWith_Cockroachdb  \\\n",
      "0                                   0   \n",
      "1                                   0   \n",
      "2                                   0   \n",
      "3                                   0   \n",
      "4                                   0   \n",
      "\n",
      "   DatabaseHaveWorkedWith_Microsoft_SQL_Server  \\\n",
      "0                                            0   \n",
      "1                                            0   \n",
      "2                                            0   \n",
      "3                                            0   \n",
      "4                                            0   \n",
      "\n",
      "   DatabaseHaveWorkedWith_MongoDB  DatabaseHaveWorkedWith_MySQL  \\\n",
      "0                               0                             0   \n",
      "1                               1                             0   \n",
      "2                               0                             0   \n",
      "3                               1                             1   \n",
      "4                               0                             0   \n",
      "\n",
      "   DatabaseHaveWorkedWith_Firebird  DatabaseHaveWorkedWith_Cassandra  ...  \\\n",
      "0                                0                                 0  ...   \n",
      "1                                0                                 0  ...   \n",
      "2                                0                                 0  ...   \n",
      "3                                0                                 0  ...   \n",
      "4                                0                                 0  ...   \n",
      "\n",
      "   PlatformHaveWorkedWith_Fly.io  PlatformHaveWorkedWith_Digital_Ocean  \\\n",
      "0                              0                                     0   \n",
      "1                              0                                     0   \n",
      "2                              0                                     0   \n",
      "3                              1                                     0   \n",
      "4                              0                                     0   \n",
      "\n",
      "   PlatformHaveWorkedWith_Alibaba_Cloud  \\\n",
      "0                                     0   \n",
      "1                                     0   \n",
      "2                                     0   \n",
      "3                                     0   \n",
      "4                                     0   \n",
      "\n",
      "   PlatformHaveWorkedWith_IBM_Cloud_Or_Watson  PlatformHaveWorkedWith_Netlify  \\\n",
      "0                                           0                               0   \n",
      "1                                           0                               1   \n",
      "2                                           0                               0   \n",
      "3                                           0                               0   \n",
      "4                                           0                               0   \n",
      "\n",
      "   PlatformHaveWorkedWith_Vercel  PlatformHaveWorkedWith_Microsoft_Azure  \\\n",
      "0                              0                                       0   \n",
      "1                              0                                       0   \n",
      "2                              0                                       0   \n",
      "3                              0                                       0   \n",
      "4                              0                                       0   \n",
      "\n",
      "   PlatformHaveWorkedWith_OpenStack  \\\n",
      "0                                 0   \n",
      "1                                 0   \n",
      "2                                 0   \n",
      "3                                 0   \n",
      "4                                 0   \n",
      "\n",
      "   PlatformHaveWorkedWith_Amazon_Web_Services_(AWS)  \\\n",
      "0                                                 1   \n",
      "1                                                 1   \n",
      "2                                                 0   \n",
      "3                                                 1   \n",
      "4                                                 1   \n",
      "\n",
      "   PlatformHaveWorkedWith_Managed_Hosting  \n",
      "0                                       0  \n",
      "1                                       0  \n",
      "2                                       0  \n",
      "3                                       0  \n",
      "4                                       0  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of columns to one-hot encode\n",
    "multi_value_columns = ['DatabaseHaveWorkedWith', 'PlatformHaveWorkedWith']\n",
    "\n",
    "for col in multi_value_columns:\n",
    "    # Split into lists, handle NaN, and strip whitespace\n",
    "    list_col = f'{col}_list'\n",
    "    df[list_col] = df[col].fillna('').str.split(';')\n",
    "    df[list_col] = df[list_col].apply(lambda x: [e.strip() for e in x if e.strip() != ''])\n",
    "    \n",
    "    # Get unique values\n",
    "    all_items = set([item for sublist in df[list_col] for item in sublist])\n",
    "    \n",
    "    # Create one-hot columns\n",
    "    for item in all_items:\n",
    "        col_name = f'{col}_{item.replace(\" \", \"_\")}'  # replace spaces with _ for column name\n",
    "        df[col_name] = df[list_col].apply(lambda x: int(item in x))\n",
    "    \n",
    "    # Drop the intermediate list column\n",
    "    df = df.drop(columns=[list_col])\n",
    "\n",
    "# Optional: select all new one-hot columns for review\n",
    "one_hot_cols = [c for c in df.columns if any(c.startswith(f'{col}_') for col in multi_value_columns)]\n",
    "print(df[one_hot_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\roths\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\iostream.py\", line 684, in write\n",
      "    self._buffers[frozenset(parent.items())].write(string)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to an Excel file\n",
    "output_file = 'survey_data_processed.xlsx'\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"File saved successfully as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AINextMuch less integrated    64289\n",
      "AINextLess integrated         63082\n",
      "AINextNo change               52939\n",
      "AINextMuch more integrated    51999\n",
      "EmbeddedAdmired               48704\n",
      "                              ...  \n",
      "Lang_Swift                        0\n",
      "Lang_Java                         0\n",
      "Lang_Kotlin                       0\n",
      "Lang_F#                           0\n",
      "Lang_Clojure                      0\n",
      "Length: 173, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Sort columns by descending number of missing values\n",
    "missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "\n",
    "print(missing_values_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseId        0\n",
      "CompTotal         0\n",
      "WorkExp           0\n",
      "JobSatPoints_1    0\n",
      "JobSatPoints_4    0\n",
      "                 ..\n",
      "Lang_Swift        0\n",
      "Lang_Java         0\n",
      "Lang_Kotlin       0\n",
      "Lang_F#           0\n",
      "Lang_Clojure      0\n",
      "Length: 72, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Select all numerical columns\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Fill missing values with mean\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].mean())\n",
    "\n",
    "print(df[num_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0    Remote\n",
      "1    Remote\n",
      "2    Remote\n",
      "3    Hybrid\n",
      "4    Hybrid\n",
      "Name: RemoteWork, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "remote_mapping = {\n",
    "    \"Remote\": \"Remote\",\n",
    "    \"Hybrid (some remote, some in-person)\": \"Hybrid\",\n",
    "    \"In-Person\": \"In-Person\"\n",
    "}\n",
    "\n",
    "df['RemoteWork'] = df['RemoteWork'].replace(remote_mapping)\n",
    "\n",
    "# Fill missing values in RemoteWork with its own mode\n",
    "mode_val = df['RemoteWork'].mode()\n",
    "\n",
    "if not mode_val.empty:\n",
    "    df['RemoteWork'] = df['RemoteWork'].fillna(mode_val[0])\n",
    "\n",
    "print(df['RemoteWork'].isnull().sum())\n",
    "print(df['RemoteWork'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_scaled\n",
      "0         86155.287263                      0.0053\n",
      "1         86155.287263                      0.0053\n",
      "2         86155.287263                      0.0053\n",
      "3         86155.287263                      0.0053\n",
      "4         86155.287263                      0.0053\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "df_scaled = df.copy()  # optional, defragments\n",
    "df_scaled['ConvertedCompYearly_scaled'] = (\n",
    "    df_scaled['ConvertedCompYearly'] - df_scaled['ConvertedCompYearly'].min()\n",
    ") / (df_scaled['ConvertedCompYearly'].max() - df_scaled['ConvertedCompYearly'].min())\n",
    "\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_scaled']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original skewness: 88.42916521218113\n",
      "Skewness after Yeo-Johnson: 1.705571373785527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\2658204710.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ConvertedCompYearly_transformed'] = pt.fit_transform(df[['ConvertedCompYearly']]).flatten()\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')  # Works with zero and positive values\n",
    "df['ConvertedCompYearly_transformed'] = pt.fit_transform(df[['ConvertedCompYearly']]).flatten()\n",
    "\n",
    "print(\"Original skewness:\", df['ConvertedCompYearly'].skew())\n",
    "print(\"Skewness after Yeo-Johnson:\", df['ConvertedCompYearly_transformed'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  YearsCodePro  YearsCodePro_numeric ExperienceLevel\n",
      "0            2                   2.0          Junior\n",
      "1           17                  17.0          Expert\n",
      "2           27                  27.0          Expert\n",
      "3            2                   2.0          Junior\n",
      "4            2                   2.0          Junior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\4084127056.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['YearsCodePro_numeric'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
      "C:\\Users\\roths\\AppData\\Local\\Temp\\ipykernel_4152\\4084127056.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ExperienceLevel'] = pd.cut(df['YearsCodePro_numeric'], bins=bins, labels=labels, right=True)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# First, convert 'YearsCodePro' to numeric, handling non-numeric entries\n",
    "df['YearsCodePro_numeric'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# Define bins and labels\n",
    "bins = [0, 2, 5, 10, float('inf')]  # ranges in years\n",
    "labels = ['Junior', 'Intermediate', 'Senior', 'Expert']\n",
    "\n",
    "# Create the 'ExperienceLevel' column\n",
    "df['ExperienceLevel'] = pd.cut(df['YearsCodePro_numeric'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Optional: check result\n",
    "print(df[['YearsCodePro', 'YearsCodePro_numeric', 'ExperienceLevel']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
